{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"9.2 Building a DL model for Transcript Generation.ipynb","provenance":[],"authorship_tag":"ABX9TyPQfWL2XtF6TBBCmz3m1I+A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3b85a134a6a54a368e956d17a19dca5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dcff9d6ce6ab4384996a3cd62f3fb281","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_90c24e0f8b94404f98fa11da3dc05f49","IPY_MODEL_b982198c87de4dff992feb127166124a"]}},"dcff9d6ce6ab4384996a3cd62f3fb281":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90c24e0f8b94404f98fa11da3dc05f49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0c044a981748433091093d8012cd6a71","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":182379138,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":182379138,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b032640c7bc94c67b0fd8f203c1584f2"}},"b982198c87de4dff992feb127166124a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfb58706fa314c70a8c6484f10dbc8e5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 174M/174M [09:08&lt;00:00, 332kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4581fa50e8b463a8aa440cb622b8868"}},"0c044a981748433091093d8012cd6a71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b032640c7bc94c67b0fd8f203c1584f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfb58706fa314c70a8c6484f10dbc8e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4581fa50e8b463a8aa440cb622b8868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"raGw_6RStpVr"},"source":["## Table of Contents\n","\n","### 1. Transcript Generation using pretrained DL model\n","> #### 1.1 Install required libraries\n","> #### 1.2 Initialize DL model\n","> #### 1.3 Preprocess data\n","> #### 1.4 Get prediction\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"RE8MjvlY8S_5"},"source":["### 1.1 Install required libraries"]},{"cell_type":"code","metadata":{"id":"hEhgX0TKlltp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617276268584,"user_tz":-330,"elapsed":5639,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}},"outputId":"b8524719-a3b1-46c9-bcf8-b393c3522f35"},"source":["# install important libraries\n","!pip install -q omegaconf soundfile torchaudio # audio processing libs"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.9MB 11.3MB/s \n","\u001b[K     |████████████████████████████████| 645kB 39.5MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2ZpaJXII8Vi7"},"source":["### 1.2 Initialize DL model"]},{"cell_type":"code","metadata":{"id":"0Tdu-x8Rm31z","executionInfo":{"status":"ok","timestamp":1617276288315,"user_tz":-330,"elapsed":3874,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}}},"source":["# import pytorch related modules\n","import torch\n","import torchaudio"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["3b85a134a6a54a368e956d17a19dca5d","dcff9d6ce6ab4384996a3cd62f3fb281","90c24e0f8b94404f98fa11da3dc05f49","b982198c87de4dff992feb127166124a","0c044a981748433091093d8012cd6a71","b032640c7bc94c67b0fd8f203c1584f2","bfb58706fa314c70a8c6484f10dbc8e5","e4581fa50e8b463a8aa440cb622b8868"]},"id":"bPfIyBpBmm3q","executionInfo":{"status":"ok","timestamp":1617276962474,"user_tz":-330,"elapsed":29088,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}},"outputId":"14c84d51-4eeb-4abc-a2e7-4acc6d4d01f9"},"source":["# download model from torch hub\n","model, decoder, utils = torch.hub.load('snakers4/silero-models', model='silero_stt', language='en')\n","\n","# import required modules/utilities\n","(read_batch, split_into_batches, read_audio, prepare_model_input) = utils    "],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/snakers4/silero-models/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b85a134a6a54a368e956d17a19dca5d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=182379138.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cODtdi6ZnBIw"},"source":["**Note - Upload a video file**"]},{"cell_type":"markdown","metadata":{"id":"OvFL43bf8Z9K"},"source":["### 1.3 Preprocess data"]},{"cell_type":"code","metadata":{"id":"qbzJ0U5zm2Uh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617277131266,"user_tz":-330,"elapsed":2099,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}},"outputId":"aa1aacf8-1e7f-4932-d402-ceed6ee9f79b"},"source":["# extract audio from the video\n","!ffmpeg -i 'video.mp4' -vn -acodec copy audio.aac\n","!ffmpeg -i audio.aac audio.wav"],"execution_count":4,"outputs":[{"output_type":"stream","text":["ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video.mp4':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf57.83.100\n","  Duration: 00:00:14.90, start: 0.033008, bitrate: 1548 kb/s\n","    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 1280x720, 1408 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n","    Metadata:\n","      handler_name    : VideoHandler\n","    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 132 kb/s (default)\n","    Metadata:\n","      handler_name    : SoundHandler\n","Output #0, adts, to 'audio.aac':\n","  Metadata:\n","    major_brand     : isom\n","    minor_version   : 512\n","    compatible_brands: isomiso2avc1mp41\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 132 kb/s (default)\n","    Metadata:\n","      handler_name    : SoundHandler\n","Stream mapping:\n","  Stream #0:1 -> #0:0 (copy)\n","Press [q] to stop, [?] for help\n","size=     246kB time=00:00:14.87 bitrate= 135.3kbits/s speed=6.08e+03x    \n","video:0kB audio:241kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.980102%\n","ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","\u001b[0;35m[aac @ 0x55eb8e74e000] \u001b[0m\u001b[0;33mEstimating duration from bitrate, this may be inaccurate\n","\u001b[0mInput #0, aac, from 'audio.aac':\n","  Duration: 00:00:16.07, bitrate: 125 kb/s\n","    Stream #0:0: Audio: aac (LC), 48000 Hz, stereo, fltp, 125 kb/s\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n","Press [q] to stop, [?] for help\n","Output #0, wav, to 'audio.wav':\n","  Metadata:\n","    ISFT            : Lavf57.83.100\n","    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 48000 Hz, stereo, s16, 1536 kb/s\n","    Metadata:\n","      encoder         : Lavc57.107.100 pcm_s16le\n","size=    2792kB time=00:00:14.89 bitrate=1536.0kbits/s speed= 620x    \n","video:0kB audio:2792kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002728%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JEN9n0twnI7C","executionInfo":{"status":"ok","timestamp":1617277216810,"user_tz":-330,"elapsed":1174,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}}},"source":["# preprocess input audio\n","test_files = ['audio.wav']\n","batches = split_into_batches(test_files, batch_size=10)\n","preprocessed_batch = prepare_model_input(read_batch(batches[0]))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rlhBgTRf8emw"},"source":["### 1.4 Get prediction"]},{"cell_type":"code","metadata":{"id":"Lwj_uApMsMkA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617277307391,"user_tz":-330,"elapsed":2949,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}},"outputId":"16b12a5a-b5ef-4f3e-9d49-5baa78e0b387"},"source":["# send input to model to get prediction\n","text = \"\"\n","output = model(preprocessed_batch)\n","for example in output:\n","    # decode output to human readable format\n","    pred = decoder(example.cpu())\n","    text = text + pred"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:889: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:639.)\n","  result = self.forward(*input, **kwargs)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"_oOI3DVQsRpM","executionInfo":{"status":"ok","timestamp":1617277307393,"user_tz":-330,"elapsed":1117,"user":{"displayName":"Faizan Shaikh","photoUrl":"","userId":"11428351120800485612"}},"outputId":"98b1fbf3-cdf7-4326-981d-32deaec9b563"},"source":["text"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'hello and welcome back to lo in this coes we have covered two of the commonly used tools for model deployment which are streamlit and amazon web services all'"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Tyldbr16tRg4"},"source":[""],"execution_count":null,"outputs":[]}]}